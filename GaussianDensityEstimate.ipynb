{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "from mnist import MNIST\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define Kernel density estimation using gaussian kernel\n",
    "def Gausskernel(x_a,x_b,sigma):\n",
    "    len_train = len(x_a)\n",
    "    len_val = len(x_b)\n",
    "    d = len(x_a[0].astype(np.float64))\n",
    "    mu = x_a.astype(np.float64)\n",
    "    # the term log(1/K) where k is all the elements in the set\n",
    "    ln_k = np.log(len_train)\n",
    "    #denominator 2σ^2\n",
    "    denom = 2*(sigma**2)\n",
    "    # the term 0.5(log(2πσ^2) is constant\n",
    "    t = -(0.5*d)*np.log((np.pi*denom))\n",
    "    p_x = 0\n",
    "    for i in range(len_train):\n",
    "        x = x_b[i].astype(np.float64)\n",
    "        t1 = np.sum((-(x-mu)**2)/denom, axis=1)\n",
    "        a = np.max(t1)\n",
    "        sum_ele = np.sum(np.exp(t1 - a))\n",
    "        log_p = a + np.log(sum_ele)\n",
    "        p_x += log_p\n",
    "    f = t - ln_k +p_x / len_val\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load MNIST Data\n",
    "mndata = MNIST('.\\data\\MNIST')\n",
    "mndata.gz = True\n",
    "images_train, labels_train = mndata.load_training()\n",
    "# or\n",
    "images_test, labels_test = mndata.load_testing()\n",
    "images_train = np.array(images_train)\n",
    "images_test = np.array(images_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "............................\n",
      "............................\n",
      "............................\n",
      "............................\n",
      "................@@@@........\n",
      "................@@@@........\n",
      "................@@@@........\n",
      "...............@@@@@........\n",
      "...............@@@@.........\n",
      "...............@@@@.........\n",
      "..............@@@@@.........\n",
      "..............@@@@@.........\n",
      "..............@@@@@.........\n",
      ".............@@@@@@.........\n",
      ".............@@@@@..........\n",
      "............@@@@@...........\n",
      "...........@@@@@............\n",
      "...........@@@@@............\n",
      "...........@@@@@............\n",
      "..........@@@@@.............\n",
      ".........@@@@@..............\n",
      "........@@@@@@..............\n",
      "........@@@@@...............\n",
      "........@@@@@............@..\n",
      "............................\n",
      "............................\n",
      "............................\n",
      "............................\n"
     ]
    }
   ],
   "source": [
    "#Print random data \n",
    "index = random.randrange(0, len(images_train))  # choose an index ;-)\n",
    "print(mndata.display(images_train[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "#Carve out train, validationa nd test sets and preprocess by scaling values\n",
    "np.random.shuffle(images_train)\n",
    "\n",
    "X_train = images_train[0:10000]\n",
    "X_valid = images_train[10000:20000]\n",
    "X_test = images_test\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "X_valid = np.array(X_valid)\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "X_train = X_train/255\n",
    "X_valid = X_valid/255\n",
    "X_test = X_test/255\n",
    "\n",
    "print(np.max(X_train))\n",
    "print(np.min(X_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-7900.898101127743, -2465.3892320360337, -1300.951063591691, -58.53131190753254, -276.79438448310384, -748.6145108829477, -1052.944381440686, -1273.3483799745331]\n",
      "--- 0.0280001163482666 seconds ---\n",
      "-77.21941571962122\n"
     ]
    }
   ],
   "source": [
    "# Grid-search for the optimal value of sigma, returning the log-probability of each sigma\n",
    "sigmas = [0.05, 0.08, 0.1, 0.2, 0.5, 1.0, 1.5, 2.0 ]\n",
    "p = [kernel(X_train[0:100],X_valid[0:100],sigma) for sigma in sigma_range]\n",
    "print (p)\n",
    "indx = np.argmax(p)\n",
    "# log-probability for optimal sigma and calculate time\n",
    "start_time = time.time()\n",
    "sigmax = Gausskernel(X_train[0:100],X_test[0:100],sigmas[indx])\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print (sigmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load CIFAR_100 Data and carve out train, validation and test sets and scale values (pre-process)\n",
    "\n",
    "def unpickle(file):\n",
    "    fo = open(file, 'rb')\n",
    "    u = pickle._Unpickler( fo )\n",
    "    u.encoding = 'latin1'\n",
    "    dict = u.load()\n",
    "    fo.close()\n",
    "    return dict\n",
    "\n",
    "def load_files(train_dir, test_dir):\n",
    "    Train = unpickle(train_dir)\n",
    "    Test = unpickle(test_dir)\n",
    "    X_training =Train['data'].astype(np.float64)\n",
    "    X_training = X_training/255\n",
    "    np.random.shuffle(X_training)\n",
    "    X_train = X_training[0:10000]\n",
    "    X_valid = X_training[10000:20000]\n",
    "    X_test =Test['data'].astype(np.float64)\n",
    "    X_test = X_test/255\n",
    "    return X_train, X_valid, X_test\n",
    "\n",
    "X_train_c, X_valid_c, X_test_c = load_files('./data/cifar-100-python/train', './data/cifar-100-python/test') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-22103.404372850302, -6193.041706017947, -2873.7194890367828, 336.6969672859834, -982.9962640304133, -2898.6909295429705, -4104.632894519445, -4974.396457961507]\n",
      "70.6630225740596\n",
      "--- 0.7890000343322754 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# Grid-search for the optimal value of sigma, returning the log-probability of each sigma\n",
    "sigmas = [0.05, 0.08, 0.1, 0.2, 0.5, 1.0, 1.5, 2.0]\n",
    "p = [kernel(X_train_c[0:10000],X_valid_c[0:10000],sigma) for sigma in sigmas]\n",
    "print (p)\n",
    "indx = np.argmax(p)\n",
    "start_time = time.time()\n",
    "# log-probability for optimal sigma and calculate time\n",
    "sigmax = Gausskernel(X_train_c[0:10000],X_test_c[0:10000],sigmas[indx])\n",
    "print (sigmax)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
